{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP1pAit7mt8iNUGwwmBdC/A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sufiyansayyed19/LLM_Learning/blob/main/Day5_Business_Brochure_Solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a98030af-fcd1-4d63-a36e-38ba053498fa"
      },
      "source": [
        "# A full business solution\n",
        "\n",
        "## Now we will take our project from Day 1 to the next level\n",
        "\n",
        "### BUSINESS CHALLENGE:\n",
        "\n",
        "Create a product that builds a Brochure for a company to be used for prospective clients, investors and potential recruits.\n",
        "\n",
        "We will be provided a company name and their primary website.\n",
        "\n",
        "See the end of this notebook for examples of real-world business applications.\n",
        "\n",
        "And remember: I'm always available if you have problems or ideas! Please do reach out."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All imports  \n",
        "import os  \n",
        "import json  \n",
        "from IPython.display import Markdown, display, update_display  \n",
        "from google.colab import userdata  \n",
        "from openai import OpenAI   "
      ],
      "metadata": {
        "id": "XOuPcjxNH2UX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b71dc62"
      },
      "source": [
        "## 1.Scraper Functions\n",
        "\n",
        "This section defines functions to scrape website content and extract links. These functions are crucial for gathering the necessary information to create the brochure."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get website content"
      ],
      "metadata": {
        "id": "bRe2J2X79cgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Install necessary libraries\n",
        "!pip install beautifulsoup4 requests markdownify\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "# --- THESE ARE THE FUNCTIONS ED HAS IN 'scraper.py' ---\n",
        "\n",
        "def fetch_website_contents(url):\n",
        "    \"\"\"\n",
        "    Fetches the text content of a website, stripping out scripts and styles.\n",
        "    \"\"\"\n",
        "    print(f\"Scraping: {url}...\")\n",
        "    try:\n",
        "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Remove script and style elements\n",
        "        for script in soup([\"script\", \"style\", \"nav\", \"footer\"]):\n",
        "            script.extract()\n",
        "\n",
        "        # Get text\n",
        "        text = soup.get_text()\n",
        "\n",
        "        # Break into lines and remove leading/trailing space on each\n",
        "        lines = (line.strip() for line in text.splitlines())\n",
        "        # Break multi-headlines into a line each\n",
        "        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
        "        # Drop blank lines\n",
        "        text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
        "\n",
        "        return text[:5000] # Limit to 5000 chars to save tokens\n",
        "    except Exception as e:\n",
        "        return f\"Error fetching {url}: {e}\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rmDY2JYsZFP",
        "outputId": "f536bf08-d74c-4021-8765-981751d9a7a6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Collecting markdownify\n",
            "  Downloading markdownify-1.2.2-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n",
            "Requirement already satisfied: six<2,>=1.15 in /usr/local/lib/python3.12/dist-packages (from markdownify) (1.17.0)\n",
            "Downloading markdownify-1.2.2-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: markdownify\n",
            "Successfully installed markdownify-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get website links"
      ],
      "metadata": {
        "id": "3ZgcBfa09n5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_website_links(url):\n",
        "    \"\"\"\n",
        "    Fetches all links from a website and converts relative links to absolute.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        links = []\n",
        "        for a_tag in soup.find_all('a', href=True):\n",
        "            href = a_tag['href']\n",
        "            # Convert relative links (e.g. \"/about\") to full links\n",
        "            full_url = urljoin(url, href)\n",
        "            if full_url.startswith('http'):\n",
        "                links.append(full_url)\n",
        "\n",
        "        # Remove duplicates\n",
        "        return list(set(links))\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching links: {e}\")\n",
        "        return []\n",
        "\n",
        "print(\"Scraper functions loaded!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_4BOmw4CGie",
        "outputId": "b2b83385-6bbe-47b7-ee39-6e8683bcb470"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraper functions loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.API Key Set Up for colab"
      ],
      "metadata": {
        "id": "Oo2bSfjWCs3P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ADD key value in secret and check with code below"
      ],
      "metadata": {
        "id": "5efi86FbDE1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "    key = userdata.get('OPENAI_API_KEY')\n",
        "    print(f\"Success! Key found. It starts with: {key[:8]}...\")\n",
        "except Exception as e:\n",
        "    print(\"Error: Could not find key. Did you turn the toggle switch ON?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9UsV4rvCmzl",
        "outputId": "be2e5271-7add-4cd5-9f5c-c36109d2727a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success! Key found. It starts with: sk-or-v1...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.API Call Setup"
      ],
      "metadata": {
        "id": "ZFqTdU0cCmDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        " #1. Setup API Key (Make sure you added OPENAI_API_KEY in Colab Secrets)\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# 2. Setup Client (OpenRouter)\n",
        "client = OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
        ")\n",
        "\n",
        "# 3. Define Models\n",
        "# We use a cheap, fast model for link selection\n",
        "LINK_MODEL = \"openai/gpt-4o-mini\"\n",
        "# We use a smarter model for writing the brochure\n",
        "WRITER_MODEL = \"openai/gpt-4o-mini\"\n",
        "\n",
        "print(\"Client and Models configured!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3T7JqqcQDSNl",
        "outputId": "840209d6-d5b9-429a-dec8-2dcedc590cf3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client and Models configured!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.Prompt Design"
      ],
      "metadata": {
        "id": "j1fG7HjvD7Ss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### i-System Prompts"
      ],
      "metadata": {
        "id": "T5NGVF2xEuIX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Link system prompt"
      ],
      "metadata": {
        "id": "pbOqTLRwEGL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- SYSTEM PROMPTS ---\n",
        "link_system_prompt = \"\"\"\n",
        "You are provided with a list of links found on a webpage.\n",
        "You are able to decide which of the links would be most relevant to include in a brochure about the company,\n",
        "such as links to an About page, or a Company page, or Careers/Jobs pages.\n",
        "You should respond in JSON as in this example:\n",
        "{\n",
        "    \"links\": [\n",
        "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
        "        {\"type\": \"careers page\", \"url\": \"https://another.full.url/careers\"}\n",
        "    ]\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "v1sS1VNKELI3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Brochure System prompt"
      ],
      "metadata": {
        "id": "kdLVdcjkEKx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "brochure_system_prompt = \"\"\"\n",
        "You are an assistant that analyzes the contents of several relevant pages from a company website\n",
        "and creates a short brochure about the company for prospective customers, investors and recruits.\n",
        "Respond in markdown without code blocks.\n",
        "Include details of company culture, customers and careers/jobs if you have the information.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "r7yXHznrEWpw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ii- User Prompt"
      ],
      "metadata": {
        "id": "O2vtREAtEWEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### User prompt to select relevent links"
      ],
      "metadata": {
        "id": "Am-i2SZWFlMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_links_user_prompt(url):\n",
        "    raw_links = fetch_website_links(url)\n",
        "    # Take only first 30 links to save tokens\n",
        "    links_text = \"\\n\".join(raw_links[:30])\n",
        "    user_prompt = f\"\"\"\n",
        "    Here is the list of links on the website {url} -\n",
        "    Please decide which of these are relevant web links for a brochure about the company,\n",
        "    respond with the full https URL in JSON format.\n",
        "    Do not include Terms of Service, Privacy, email links.\n",
        "\n",
        "    Links:\n",
        "    {links_text}\n",
        "    \"\"\"\n",
        "    return user_prompt"
      ],
      "metadata": {
        "id": "5KVwcXSSEmlV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### User prompt to Create brochure"
      ],
      "metadata": {
        "id": "ENvg4TX8Ft5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_brochure_user_prompt(company_name, url):\n",
        "    print(\"üì• Fetching website content (this takes a moment)...\")\n",
        "    content = fetch_page_and_all_relevant_links(url)\n",
        "\n",
        "    user_prompt = f\"\"\"\n",
        "    You are looking at a company called: {company_name}\n",
        "    Here are the contents of its landing page and other relevant pages;\n",
        "    use this information to build a short brochure of the company in markdown without code blocks.\\n\\n\n",
        "    {content[:10000]}\n",
        "    \"\"\"\n",
        "    # (Limited to 10k chars to ensure we don't overflow context)\n",
        "    return user_prompt"
      ],
      "metadata": {
        "id": "yhK-YKyRFNe_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.Content Get functions"
      ],
      "metadata": {
        "id": "yxn58MNXF628"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Page and all Links function"
      ],
      "metadata": {
        "id": "yEtZODgdGkdu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_page_and_all_relevant_links(url):\n",
        "    # 1. Get Main Page\n",
        "    contents = fetch_website_contents(url)\n",
        "\n",
        "    # 2. Get Relevant Links\n",
        "    relevant_links = select_relevant_links(url)\n",
        "\n",
        "    result = f\"## Landing Page:\\n\\n{contents}\\n## Relevant Links:\\n\"\n",
        "\n",
        "    # 3. Get Content of Relevant Links\n",
        "    for link in relevant_links['links']:\n",
        "        print(f\"   Reading: {link['type']} ({link['url']})\")\n",
        "        link_content = fetch_website_contents(link[\"url\"])\n",
        "        result += f\"\\n\\n### Link: {link['type']}\\n{link_content}\"\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "h2VNR8AwFLQr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select relevant links from all links"
      ],
      "metadata": {
        "id": "Y1-x1-hrGuot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def select_relevant_links(url):\n",
        "    print(f\"üîç Analyzing links for {url}...\")\n",
        "    response = client.chat.completions.create(\n",
        "        model=LINK_MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
        "            {\"role\": \"user\", \"content\": get_links_user_prompt(url)}\n",
        "        ],\n",
        "        response_format={\"type\": \"json_object\"}\n",
        "    )\n",
        "    result = response.choices[0].message.content\n",
        "    try:\n",
        "        links = json.loads(result)\n",
        "        print(f\"‚úÖ Found {len(links['links'])} relevant links.\")\n",
        "        return links\n",
        "    except:\n",
        "        print(\"Error parsing JSON\")\n",
        "        return {\"links\": []}"
      ],
      "metadata": {
        "id": "xiZFm_ukE-i5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.Brochure Generator function"
      ],
      "metadata": {
        "id": "GwnCMvLqG8Gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display, update_display\n",
        "\n",
        "def stream_brochure(company_name, url):\n",
        "    print(f\"üöÄ Generating brochure for {company_name}...\")\n",
        "    stream = client.chat.completions.create(\n",
        "        model=WRITER_MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": brochure_system_prompt},\n",
        "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
        "          ],\n",
        "        stream=True\n",
        "    )\n",
        "    response = \"\"\n",
        "    display_handle = display(Markdown(\"Wait for it...\"), display_id=True)\n",
        "    for chunk in stream:\n",
        "        content = chunk.choices[0].delta.content or ''\n",
        "        response += content\n",
        "        update_display(Markdown(response), display_id=display_handle.display_id)"
      ],
      "metadata": {
        "id": "LUr7JaT5FQZs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.Driver"
      ],
      "metadata": {
        "id": "vobZ53M1HDIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- RUN IT! ---\n",
        "# Use standard HuggingFace URL\n",
        "stream_brochure(\"HuggingFace\", \"https://huggingface.co\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fJP_v1QKFSXD",
        "outputId": "c6ede1a3-8614-4094-a330-8a541997aa16"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Generating brochure for HuggingFace...\n",
            "üì• Fetching website content (this takes a moment)...\n",
            "Scraping: https://huggingface.co...\n",
            "üîç Analyzing links for https://huggingface.co...\n",
            "‚úÖ Found 6 relevant links.\n",
            "   Reading: about page (https://huggingface.co/docs)\n",
            "Scraping: https://huggingface.co/docs...\n",
            "   Reading: blog page (https://huggingface.co/blog)\n",
            "Scraping: https://huggingface.co/blog...\n",
            "   Reading: careers page (https://huggingface.co/enterprise)\n",
            "Scraping: https://huggingface.co/enterprise...\n",
            "   Reading: pricing page (https://huggingface.co/pricing)\n",
            "Scraping: https://huggingface.co/pricing...\n",
            "   Reading: models page (https://huggingface.co/models)\n",
            "Scraping: https://huggingface.co/models...\n",
            "   Reading: learn page (https://huggingface.co/learn)\n",
            "Scraping: https://huggingface.co/learn...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Hugging Face: The AI Community Building the Future\n\nWelcome to **Hugging Face**, a pioneering platform designed for collaboration in the machine learning community. Our mission is to empower developers, researchers, and organizations to build and share cutting-edge AI models, datasets, and applications. With over 2 million models and numerous powerful applications, we are at the forefront of AI innovation.\n\n## Company Culture\n\nAt Hugging Face, we foster a collaborative and open community that encourages diversity, creativity, and innovation. Our culture is built on shared knowledge and a passion for pushing the boundaries of AI technology. We believe in the influence of collective intelligence, and that‚Äôs why we prioritize open-source contributions, welcoming individuals from all backgrounds to join us in shaping the future of machine learning. \n\n## Our Community\n\nMore than 50,000 organizations rely on Hugging Face to advance their projects, including tech giants such as Microsoft, Google, Amazon, and Meta. Our platform hosts a vibrant ecosystem where users can find and share information to accelerate their machine learning journey. The community-driven nature of our platform ensures continuous evolution, with a vast repository of state-of-the-art models and resources.\n\n## Products and Services\n\n- **Collaboration Platform**: Host and collaborate on unlimited public models and datasets.\n- **Open Source Tools**: Access state-of-the-art libraries like Transformers for PyTorch and Diffusers.\n- **Compute Solutions**: Paid options for enhanced computational power and enterprise-level support starting at just $20 per user per month.\n- **Enterprise Features**: Advanced security and access controls for teams, tailored to meet the needs of organizations.\n\n## Careers at Hugging Face\n\nWe are always on the lookout for passionate and innovative talent to join our growing team. At Hugging Face, you will have the opportunity to work with cutting-edge machine learning technologies and collaborate with industry experts. We value diversity and encourage applicants from all walks of life to apply and bring their unique perspectives to our community.\n\n## Join Us\n\nReady to be a part of something groundbreaking? \n\n- **Explore AI Apps**  \n- **Browse Models and Datasets**  \n- **Contribute to Open Source**  \n- **Grow your Career with Us**  \n\nAt Hugging Face, we believe the future of AI lies in collaboration and accessibility. Let‚Äôs build it together!"
          },
          "metadata": {}
        }
      ]
    }
  ]
}