{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQ++ieUc8VsS5e8enwJqQi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sufiyansayyed19/LLM_Learning/blob/main/W2D1_playWithAPIs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling Different APIs"
      ],
      "metadata": {
        "id": "ft5c4Q-_wQ5D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API key setup"
      ],
      "metadata": {
        "id": "ueT2cNNBwZRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "open_route_api_key = userdata.get(\"OPEN_ROUTE_API_KEY\")\n",
        "gemini_api_key = userdata.get(\"GEMINI_API_KEY\")"
      ],
      "metadata": {
        "id": "H9UsV4rvCmzl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Keys"
      ],
      "metadata": {
        "id": "2Ui5Uma-4uzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if open_route_api_key:\n",
        "  print(\"open_route api key is good.\")\n",
        "else:\n",
        "  print(\"open_route api key not found.\")\n",
        "\n",
        "if gemini_api_key:\n",
        "  print(\"gemini_api_key is good.\")\n",
        "else:\n",
        "  print(\"gemini_api key not found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItAESYLoPo5g",
        "outputId": "54203d08-905d-4fb1-bbec-586c4ffbfead"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "open_route api key is good.\n",
            "gemini_api_key is good.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Url and base set up"
      ],
      "metadata": {
        "id": "tXw_9VsK4y21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        "open_route_url = \"https://openrouter.ai/api/v1\""
      ],
      "metadata": {
        "id": "UULyfUEpQNRL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "-K2XIPolTFqU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openroute = OpenAI(base_url=open_route_url,api_key=open_route_api_key)\n",
        "\n",
        "gemini = OpenAI(base_url=gemini_url, api_key=gemini_api_key)"
      ],
      "metadata": {
        "id": "JDYi5f_aTJ6D"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## User prompt"
      ],
      "metadata": {
        "id": "z2YHTMHt45vM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tell_a_joke = [\n",
        "    { \"role\": \"user\", \"content\":\"Tell a joke for a student on the journey to becoming an expert in LLM Engineering\",    }\n",
        "]"
      ],
      "metadata": {
        "id": "zLJp9tubQws-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API call with markdown"
      ],
      "metadata": {
        "id": "pCsUVtV449sV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OpenRoute"
      ],
      "metadata": {
        "id": "J2LPzeCj5Biu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown,display\n",
        "\n",
        "response = openroute.chat.completions.create(\n",
        "    model=\"openai/gpt-4o-mini\",\n",
        "    messages=tell_a_joke\n",
        ")\n",
        "\n",
        "display(Markdown(response.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "qPbhKdf0SFms",
        "outputId": "3bf6c44e-a608-4ba0-9122-3336c9c7e4cd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Why did the LLM engineering student bring a ladder to class?\n\nBecause they heard the course was about climbing the ranks in AI!"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gemini"
      ],
      "metadata": {
        "id": "IeN5iedX5GMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = gemini.chat.completions.create(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    messages=tell_a_joke)\n",
        "display(Markdown(response.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "fVjcydzWSs7c",
        "outputId": "288b15a5-634c-4f52-b1af-22e4317ef3cd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "What's an LLM engineer's favorite question after finally getting their model to produce the *perfect*, insightful, and factual response on a tricky query?\n\n\"Okay, but can it do *that* consistently across 10,000 different edge cases without blowing up the context window, hallucinating about quantum-entangled teacups, or costing me a small fortune in API calls?\""
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gemini Base code (alternative to openai - not commonly used)"
      ],
      "metadata": {
        "id": "WqsNI_Fb5lHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash-lite\", contents=\"Describe the color Blue to someone who's never been able to see in 1 sentence\"\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "nvgIeJGo5j8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Antrophhic Base code (alternative to openai - not commonly used)"
      ],
      "metadata": {
        "id": "BBhOn_qB5r6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from anthropic import Anthropic\n",
        "\n",
        "client = Anthropic()\n",
        "\n",
        "response = client.messages.create(\n",
        "    model=\"claude-sonnet-4-5-20250929\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Describe the color Blue to someone who's never been able to see in 1 sentence\"}],\n",
        "    max_tokens=100\n",
        ")\n",
        "print(response.content[0].text)"
      ],
      "metadata": {
        "id": "tTwZMk625YTd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}